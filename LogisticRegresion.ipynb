{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Logistic Regression**\n"
      ],
      "metadata": {
        "id": "J29otaM_hXRk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Assignment Questions**"
      ],
      "metadata": {
        "id": "LzMcaLLQhnEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Theoretical**"
      ],
      "metadata": {
        "id": "rgJSr_G9hvl9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.What is Logistic Regression, and how does it differ from Linear Regression?**"
      ],
      "metadata": {
        "id": "6KJAQ-FHiFOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: **Logistic Regression** is a type of regression used for predicting categorical outcomes, usually binary (yes/no, 0/1). It calculates the probability of an event happening, using an S-shaped curve (sigmoid function) to output a value between 0 and 1.\n",
        "\n",
        "**Linear Regression**, on the other hand, predicts a continuous outcome (like a price or temperature) using a straight line. It tries to fit the best line that predicts the value based on the input features.\n",
        "\n",
        "**Key Difference**:\n",
        "- **Logistic Regression** is for classification (categorical outcomes).\n",
        "- **Linear Regression** is for regression (continuous outcomes)."
      ],
      "metadata": {
        "id": "r-KSktXpiLFY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.What is the mathematical equation of Logistic Regression?**"
      ],
      "metadata": {
        "id": "DlWI14uPiUlz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: The mathematical equation of **Logistic Regression** is:\n",
        "\n",
        "\\[\n",
        "P(y = 1 \\mid X) = \\frac{1}{1 + e^{-(b_0 + b_1X_1 + b_2X_2 + \\dots + b_nX_n)}}\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( P(y = 1 \\mid X) \\) is the probability of the event occurring (the outcome being 1).\n",
        "- \\( b_0 \\) is the intercept (bias term).\n",
        "- \\( b_1, b_2, \\dots, b_n \\) are the coefficients (weights) for the input features \\( X_1, X_2, \\dots, X_n \\).\n",
        "- \\( e \\) is the base of the natural logarithm.\n",
        "- \\( X_1, X_2, \\dots, X_n \\) are the input features (independent variables).\n",
        "\n",
        "This equation uses the **sigmoid function** (the part \\( \\frac{1}{1 + e^{-z}} \\)) to ensure the output is between 0 and 1, representing a probability."
      ],
      "metadata": {
        "id": "2yRUv4MbiZKb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.Why do we use the Sigmoid function in Logistic Regression?**"
      ],
      "metadata": {
        "id": "yxl_mZrvimXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: We use the **Sigmoid function** in Logistic Regression because it maps any input value (which can be any real number) into a probability between 0 and 1, which is ideal for binary classification problems.\n",
        "\n",
        "The **Sigmoid function** has the form:\n",
        "\n",
        "\\[\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( z \\) is the linear combination of input features (e.g., \\( b_0 + b_1X_1 + b_2X_2 + \\dots \\)).\n",
        "- \\( e \\) is the base of the natural logarithm.\n",
        "\n",
        "**Why Sigmoid?**\n",
        "1. **Output between 0 and 1**: This is useful for predicting probabilities, as probabilities must be in the range [0, 1].\n",
        "2. **Non-linear transformation**: It transforms the raw linear predictions into a smooth, continuous probability curve, making it suitable for classification.\n",
        "3. **Interpretability**: The result of the Sigmoid function can be interpreted as the probability of the event happening (e.g., the probability that a customer will buy a product).\n",
        "\n",
        "In short, the Sigmoid function helps logistic regression provide meaningful predictions in terms of probabilities, making it suitable for classification tasks."
      ],
      "metadata": {
        "id": "HcFjSpoKisnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.What is the cost function of Logistic Regression?**"
      ],
      "metadata": {
        "id": "YUQ1PB-0i0eg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: The **cost function** of Logistic Regression is called the **Log Loss** or **Binary Cross-Entropy Loss**. It measures how well the model's predictions match the actual labels.\n",
        "\n",
        "The cost function for Logistic Regression is:\n",
        "\n",
        "\\[\n",
        "J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(h_{\\theta}(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_{\\theta}(x^{(i)})) \\right]\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( m \\) is the number of training examples.\n",
        "- \\( y^{(i)} \\) is the actual label (0 or 1) for the \\(i\\)-th training example.\n",
        "- \\( h_{\\theta}(x^{(i)}) \\) is the predicted probability for the \\(i\\)-th training example, given by the Sigmoid function:\n",
        "  \\[\n",
        "  h_{\\theta}(x^{(i)}) = \\frac{1}{1 + e^{-(\\theta_0 + \\theta_1 x_1^{(i)} + \\dots + \\theta_n x_n^{(i)})}}\n",
        "  \\]\n",
        "- \\( \\theta_0, \\theta_1, \\dots, \\theta_n \\) are the model's parameters (weights).\n",
        "\n",
        "### Explanation:\n",
        "- The first term \\( y^{(i)} \\log(h_{\\theta}(x^{(i)})) \\) penalizes the model more when the predicted probability is far from 1 (if the true label is 1).\n",
        "- The second term \\( (1 - y^{(i)}) \\log(1 - h_{\\theta}(x^{(i)})) \\) penalizes the model more when the predicted probability is far from 0 (if the true label is 0).\n",
        "\n",
        "The goal of training the model is to **minimize** this cost function, adjusting the parameters \\( \\theta \\) to get the best predictions (probabilities) that match the true labels."
      ],
      "metadata": {
        "id": "2O2OHYyyi5L9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.What is Regularization in Logistic Regression? Why is it needed?**"
      ],
      "metadata": {
        "id": "CpKb4hHpjDTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: **Regularization** in Logistic Regression is a technique used to **prevent overfitting** by adding a penalty to the model's cost function. This penalty discourages the model from becoming too complex and overfitting the training data.\n",
        "\n",
        "### Why is it needed?\n",
        "1. **Prevents Overfitting**: Without regularization, the model might memorize the training data (overfit) and fail to generalize well to new data. Regularization helps avoid this by controlling the model's complexity.\n",
        "2. **Improves Generalization**: By adding a penalty on large coefficients, regularization encourages the model to focus on the most important features, making it more likely to perform well on unseen data.\n",
        "\n",
        "In short, **regularization** helps make the model **simpler and more robust**, improving its ability to generalize to new, unseen data."
      ],
      "metadata": {
        "id": "fAR4XvSejIaS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.Explain the difference between Lasso, Ridge, and Elastic Net regression.**"
      ],
      "metadata": {
        "id": "9bPr7CTbjWIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans:The key difference between **Lasso**, **Ridge**, and **Elastic Net** regression lies in how they apply regularization to control model complexity and prevent overfitting. Here's a simple breakdown:\n",
        "\n",
        "### 1. **Lasso Regression (L1 Regularization)**:\n",
        "   - **Penalty term**: \\( \\lambda \\sum_{j=1}^{n} |\\theta_j| \\)\n",
        "   - **Effect**: Lasso tends to drive some coefficients exactly to **zero**, performing **feature selection** by removing irrelevant features.\n",
        "   - **When to use**: Lasso is useful when you suspect only a few features are important and want to eliminate others.\n",
        "\n",
        "### 2. **Ridge Regression (L2 Regularization)**:\n",
        "   - **Penalty term**: \\( \\frac{\\lambda}{2} \\sum_{j=1}^{n} \\theta_j^2 \\)\n",
        "   - **Effect**: Ridge shrinks the coefficients, but **does not set them to zero**. It helps to reduce multicollinearity and keeps all features but with smaller weights.\n",
        "   - **When to use**: Ridge is useful when you believe many features are important but want to prevent overfitting.\n",
        "\n",
        "### 3. **Elastic Net Regression**:\n",
        "   - **Penalty term**: Combination of Lasso and Ridge:\n",
        "     \\[\n",
        "     \\lambda \\left( \\alpha \\sum_{j=1}^{n} |\\theta_j| + \\frac{1-\\alpha}{2} \\sum_{j=1}^{n} \\theta_j^2 \\right)\n",
        "     \\]\n",
        "   - **Effect**: Elastic Net combines both L1 (Lasso) and L2 (Ridge) regularization. It provides the benefits of both: feature selection and coefficient shrinkage.\n",
        "   - **When to use**: Elastic Net is useful when you have many correlated features or when you want a balance between feature selection and shrinkage.\n",
        "\n",
        "### In short:\n",
        "- **Lasso**: Uses L1 regularization; drives some coefficients to zero (feature selection).\n",
        "- **Ridge**: Uses L2 regularization; shrinks coefficients but doesn't set them to zero.\n",
        "- **Elastic Net**: Combines L1 and L2 regularization, providing a balance of both.\n",
        "\n"
      ],
      "metadata": {
        "id": "5ELRXmoXjbPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.When should we use Elastic Net instead of Lasso or Ridge?**"
      ],
      "metadata": {
        "id": "y9N5pRsFjrEK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: You should use **Elastic Net** instead of **Lasso** or **Ridge** in the following situations:\n",
        "\n",
        "### 1. **When you have many correlated features**:\n",
        "   - **Lasso** might struggle with correlated features, as it tends to select only one feature from a group of correlated features and set others to zero.\n",
        "   - **Ridge** tends to shrink coefficients but keeps all features, even those that might be irrelevant.\n",
        "   - **Elastic Net** combines both **Lasso** and **Ridge**, so it can handle correlated features better by selecting groups of features together while still allowing for some shrinkage.\n",
        "\n",
        "### 2. **When you suspect that there are many relevant features**:\n",
        "   - **Lasso** can be too aggressive in eliminating features by setting many coefficients to zero, which might be undesirable if you believe many features are important.\n",
        "   - **Elastic Net** provides a balance between **Lasso** and **Ridge**, allowing it to both shrink the coefficients and select relevant features without eliminating too many of them.\n",
        "\n",
        "### 3. **When you have more predictors than observations**:\n",
        "   - When the number of features (predictors) is larger than the number of observations (data points), **Lasso** and **Ridge** can still work, but **Elastic Net** is more flexible and can handle this case better, especially when features are highly correlated.\n",
        "\n",
        "### When to use:\n",
        "- **Elastic Net** is preferred when you are unsure about the relationship between the features (whether they are strongly correlated or not) or if you have a mix of both relevant and irrelevant features.\n",
        "- If you know that some features are redundant (correlated), Elastic Net can help keep them together.\n",
        "\n"
      ],
      "metadata": {
        "id": "geArAgwmj4Sb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.What is the impact of the regularization parameter (λ) in Logistic Regression?**"
      ],
      "metadata": {
        "id": "4j639qkFj9Wv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: The **regularization parameter (λ)** in Logistic Regression controls the strength of the regularization applied to the model. It affects how much the model's coefficients are penalized to prevent overfitting. Here's how the regularization parameter impacts the model:\n",
        "\n",
        "### 1. **When λ is large**:\n",
        "   - **Stronger Regularization**: The model will be penalized more for having large coefficients.\n",
        "   - **Coefficients shrink more**: As λ increases, the model coefficients get **smaller**, and some might even become exactly zero (especially in Lasso or Elastic Net).\n",
        "   - **Underfitting Risk**: If λ is too large, the model might become too simple, unable to capture the underlying patterns in the data, leading to **underfitting** (low model accuracy).\n",
        "\n",
        "### 2. **When λ is small (close to zero)**:\n",
        "   - **Weaker Regularization**: The model is less penalized, and the coefficients can grow larger.\n",
        "   - **Model complexity increases**: As λ approaches zero, the regularization effect weakens, allowing the model to fit the training data more closely.\n",
        "   - **Overfitting Risk**: If λ is too small, the model might **overfit** the training data, memorizing noise and failing to generalize well to unseen data.\n",
        "\n",
        "### 3. **Optimal λ (Tuning)**:\n",
        "   - The goal is to find the optimal value of λ that provides a balance between regularization and fitting the data. This is usually done through techniques like **cross-validation**, where the model is trained with different values of λ, and the best one is chosen based on performance.\n",
        "\n",
        "### In summary:\n",
        "- **Larger λ**: More regularization, smaller coefficients, reduced overfitting, but possible underfitting.\n",
        "- **Smaller λ**: Less regularization, larger coefficients, potential overfitting.\n",
        "\n",
        "Finding the right λ helps in making the model both **accurate** and **generalizable**."
      ],
      "metadata": {
        "id": "ZE5GFphvkBn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.What are the key assumptions of Logistic Regression?**"
      ],
      "metadata": {
        "id": "xthIbJ0ukKrI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: The key assumptions of **Logistic Regression** are:\n",
        "\n",
        "1. **Binary Outcome**:\n",
        "   - Logistic regression assumes that the dependent variable (target) is **binary** or **categorical** (e.g., 0/1, yes/no, true/false).\n",
        "\n",
        "2. **Linearity of Log-Odds**:\n",
        "   - Logistic regression assumes that there is a **linear relationship** between the independent variables (features) and the **log-odds** of the outcome. This means the log of the odds of the dependent variable being 1 is a linear combination of the predictors.\n",
        "\n",
        "3. **Independence of Observations**:\n",
        "   - The observations (data points) should be **independent** of each other. Each data point should not be related to another (no autocorrelation).\n",
        "\n",
        "4. **No Multicollinearity**:\n",
        "   - The model assumes that there is **no perfect multicollinearity** among the independent variables. This means that the predictors should not be highly correlated with each other, as it can lead to instability in the model’s estimates.\n",
        "\n",
        "5. **Large Sample Size**:\n",
        "   - Logistic regression typically requires a relatively **large sample size** to provide reliable and stable estimates, especially when the number of predictors is high.\n",
        "\n",
        "6. **Homoscedasticity (for residuals)**:\n",
        "   - Though not as strict as in linear regression, logistic regression assumes that the **variance of the residuals** (errors) is constant across all levels of the independent variables.\n",
        "\n",
        "7. **No Outliers**:\n",
        "   - Logistic regression is sensitive to **outliers** in the independent variables. Extreme outliers can affect the model's estimates and predictions.\n",
        "\n"
      ],
      "metadata": {
        "id": "CdBiyZVwkPCa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10.What are some alternatives to Logistic Regression for classification tasks?**"
      ],
      "metadata": {
        "id": "k9ZfTeTZkr-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: Here are some **alternatives** to **Logistic Regression** for classification tasks:\n",
        "\n",
        "1. **Decision Trees**: Simple, interpretable, and handle non-linear relationships.\n",
        "2. **Random Forest**: Ensemble of decision trees, more accurate and robust.\n",
        "3. **Support Vector Machines (SVM)**: Effective for high-dimensional or non-linearly separable data.\n",
        "4. **k-Nearest Neighbors (k-NN)**: Simple, flexible, based on majority voting of nearest neighbors.\n",
        "5. **Naive Bayes**: Probabilistic model, works well with small or text data.\n",
        "6. **Gradient Boosting Machines (GBM)**: Sequential ensemble method, high accuracy but less interpretable.\n",
        "7. **Neural Networks**: Deep learning, effective for complex tasks like image or text classification.\n",
        "8. **K-means Clustering**: Unsupervised method, useful for clustering before classification.\n",
        "\n",
        "Each method has its strengths depending on data complexity, size, and task requirements."
      ],
      "metadata": {
        "id": "sHW6oV14kzCJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11.What are Classification Evaluation Metrics?**"
      ],
      "metadata": {
        "id": "-jkfv6V9lLz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: Here are the key **classification evaluation metrics** in short:\n",
        "\n",
        "1. **Accuracy**: Proportion of correct predictions (overall correctness).\n",
        "2. **Precision**: Correct positive predictions out of all predicted positives.\n",
        "3. **Recall**: Correct positive predictions out of all actual positives.\n",
        "4. **F1-Score**: Harmonic mean of precision and recall (balance between them).\n",
        "5. **ROC Curve & AUC**: Performance across thresholds, with AUC showing the classifier's ability to distinguish classes.\n",
        "6. **Confusion Matrix**: Table showing true positives, false positives, true negatives, and false negatives.\n",
        "7. **Specificity**: Correct negative predictions out of all actual negatives.\n",
        "8. **Log Loss**: Measures how well predicted probabilities match actual labels.\n",
        "\n",
        "The choice of metric depends on the data and the problem's needs (e.g., precision vs. recall)."
      ],
      "metadata": {
        "id": "v5kTfiUvlXDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12.How does class imbalance affect Logistic Regression?**"
      ],
      "metadata": {
        "id": "KoMM1l6hli6r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans:Class imbalance in **Logistic Regression** (and other machine learning models) occurs when one class (e.g., positive or negative) has significantly more instances than the other. This can negatively affect the model's performance in several ways:\n",
        "\n",
        "### 1. **Bias Toward the Majority Class**:\n",
        "   - The model will be biased toward predicting the majority class because it can achieve high accuracy by mostly predicting the dominant class. This can lead to poor performance on the minority class (often the more important class).\n",
        "\n",
        "### 2. **Poor Model Evaluation**:\n",
        "   - **Accuracy** becomes misleading, as a model that always predicts the majority class might still appear accurate even though it fails to predict the minority class correctly.\n",
        "   - Metrics like **precision**, **recall**, and **F1-score** are more informative for imbalanced datasets, as they focus on the performance with respect to both classes.\n",
        "\n",
        "### 3. **Overfitting on the Majority Class**:\n",
        "   - The model might **overfit** to the majority class, capturing its patterns well but missing those of the minority class, leading to poor generalization and predictive power for the minority class.\n",
        "\n",
        "### How to Handle Class Imbalance in Logistic Regression:\n",
        "\n",
        "1. **Resampling**:\n",
        "   - **Oversampling** the minority class or **undersampling** the majority class can balance the class distribution.\n",
        "   \n",
        "2. **Class Weights**:\n",
        "   - Assign higher weights to the minority class in the loss function, making the model pay more attention to misclassifications of the minority class.\n",
        "   \n",
        "3. **Alternative Metrics**:\n",
        "   - Use metrics like **Precision**, **Recall**, **F1-Score**, and **ROC-AUC** instead of accuracy to evaluate model performance.\n",
        "\n",
        "4. **Synthetic Data Generation**:\n",
        "   - Techniques like **SMOTE (Synthetic Minority Over-sampling Technique)** can generate synthetic samples for the minority class.\n"
      ],
      "metadata": {
        "id": "ENKR5rVIlm2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13.What is Hyperparameter Tuning in Logistic Regression?**"
      ],
      "metadata": {
        "id": "1FQikAPQlxDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans:**Hyperparameter tuning** in **Logistic Regression** involves adjusting parameters that control the model's behavior, such as:\n",
        "\n",
        "1. **Regularization (C or λ)**: Controls model complexity; higher values (smaller λ) reduce regularization, while lower values (larger λ) increase regularization.\n",
        "2. **Solver**: The algorithm used for optimization (e.g., **'liblinear'**, **'lbfgs'**).\n",
        "3. **Max Iterations**: The number of iterations for the solver to converge.\n",
        "4. **Penalty**: Type of regularization (**'l1'**, **'l2'**, **'elasticnet'**).\n",
        "5. **Class Weight**: Adjusts the importance of different classes, useful for imbalanced data.\n",
        "\n",
        "**Tuning methods**: **Grid search** and **random search**, often combined with **cross-validation**, help find the best hyperparameters to improve model performance."
      ],
      "metadata": {
        "id": "vldV7LMXl25i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14.What are different solvers in Logistic Regression? Which one should be used?**"
      ],
      "metadata": {
        "id": "kCqErB30mKQY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: In Logistic Regression, the solver is the algorithm used to optimize the model's coefficients. Different solvers are available, each suited for different types of problems and datasets. Here are the main solvers used in Logistic Regression:\n",
        "\n",
        "1. **'liblinear'**:\n",
        "   - **Best for**: Small datasets and **L1 regularization** (Lasso).\n",
        "   - **Use it**: When working with small or sparse datasets, or if you need feature selection via **L1 regularization**.\n",
        "\n",
        "2. **'lbfgs'**:\n",
        "   - **Best for**: Large datasets and **L2 regularization** (Ridge).\n",
        "   - **Use it**: For memory efficiency and better performance on larger datasets with **L2 regularization**.\n",
        "\n",
        "3. **'newton-cg'**:\n",
        "   - **Best for**: Large datasets and **L2 regularization**.\n",
        "   - **Use it**: When you have large datasets but fewer features and want faster convergence with **L2 regularization**.\n",
        "\n",
        "4. **'saga'**:\n",
        "   - **Best for**: Large datasets and **ElasticNet regularization** (combines **L1** and **L2**).\n",
        "   - **Use it**: When you need **ElasticNet** regularization and are dealing with large datasets.\n",
        "\n",
        "Each solver is optimized for different types of datasets and regularization needs."
      ],
      "metadata": {
        "id": "34xOdUs_mPSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15.How is Logistic Regression extended for multiclass classification?**"
      ],
      "metadata": {
        "id": "xJI3Fovomq87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: **Logistic Regression** can be extended to handle **multiclass classification** (when there are more than two classes) using two main approaches:\n",
        "\n",
        "### 1. **One-vs-Rest (OvR) / One-vs-All (OvA)**:\n",
        "   - **Concept**: This approach transforms the multiclass problem into multiple binary classification problems.\n",
        "     - For each class, we train a separate logistic regression model to distinguish that class from all others (binary classification).\n",
        "     - Each model predicts whether an instance belongs to the specific class or not.\n",
        "   - **How it works**:\n",
        "     - For **K** classes, K models are trained. Each model predicts if an instance belongs to that class (1) or not (0).\n",
        "     - The final prediction is made by selecting the class with the highest probability output from the models.\n",
        "   - **Example**: In a 3-class problem (A, B, C), we train 3 classifiers:\n",
        "     - Classifier 1: A vs. (B, C)\n",
        "     - Classifier 2: B vs. (A, C)\n",
        "     - Classifier 3: C vs. (A, B)\n",
        "\n",
        "### 2. **One-vs-One (OvO)**:\n",
        "   - **Concept**: This approach involves training a classifier for every possible pair of classes.\n",
        "     - For **K** classes, we train **K*(K-1)/2** classifiers, where each classifier distinguishes between two specific classes.\n",
        "     - Each classifier outputs the class label of the pair, and the final prediction is based on a **majority vote** from all classifiers.\n",
        "   - **Example**: For a 3-class problem (A, B, C), the classifiers are:\n",
        "     - Classifier 1: A vs. B\n",
        "     - Classifier 2: A vs. C\n",
        "     - Classifier 3: B vs. C\n",
        "\n",
        "### Which Approach to Choose?\n",
        "- **One-vs-Rest**:\n",
        "  - More efficient for **larger numbers of classes**, as only **K** classifiers are needed.\n",
        "  - Works well when classes are not mutually exclusive.\n",
        "  \n",
        "- **One-vs-One**:\n",
        "  - More accurate in some cases, especially when classes are well-separated.\n",
        "  - Requires more computation, as **K*(K-1)/2** classifiers are needed.\n"
      ],
      "metadata": {
        "id": "f1IE9wCqmzNm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16.What are the advantages and disadvantages of Logistic Regression?**"
      ],
      "metadata": {
        "id": "HmU-v_U7m9Uo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: **Advantages of Logistic Regression:**\n",
        "\n",
        "1. **Simplicity and Interpretability**:\n",
        "   - Logistic Regression is easy to implement and understand. The results are interpretable, making it easy to understand the influence of each feature on the outcome.\n",
        "\n",
        "2. **Efficiency**:\n",
        "   - It is computationally efficient and works well on small to medium-sized datasets. The model converges quickly and doesn't require a lot of memory.\n",
        "\n",
        "3. **Probabilistic Output**:\n",
        "   - Logistic Regression provides probabilistic outputs, giving the likelihood of a data point belonging to a particular class, which is useful in many real-world scenarios.\n",
        "\n",
        "4. **Works Well for Linearly Separable Data**:\n",
        "   - If the classes are linearly separable or nearly linearly separable, Logistic Regression performs very well.\n",
        "\n",
        "5. **Less Prone to Overfitting (with Regularization)**:\n",
        "   - Regularization techniques (like L2 regularization) can be used to prevent overfitting, especially when dealing with high-dimensional data.\n",
        "\n",
        "6. **Well-Established**:\n",
        "   - It's a widely used and well-studied algorithm with solid theoretical foundations.\n",
        "\n",
        "### **Disadvantages of Logistic Regression:**\n",
        "\n",
        "1. **Assumes Linear Decision Boundaries**:\n",
        "   - Logistic Regression assumes a linear relationship between the features and the log-odds of the outcome. It performs poorly if the data has complex, non-linear relationships unless you use feature engineering or transformations.\n",
        "\n",
        "2. **Sensitive to Outliers**:\n",
        "   - Logistic Regression can be sensitive to outliers in the data, which can significantly affect model performance.\n",
        "\n",
        "3. **Requires Feature Scaling**:\n",
        "   - The algorithm is sensitive to the scale of the features, so feature scaling (e.g., normalization or standardization) is usually required for better performance.\n",
        "\n",
        "4. **Struggles with Multicollinearity**:\n",
        "   - If the features are highly correlated (multicollinearity), Logistic Regression can have unstable estimates for the coefficients, making the model unreliable.\n",
        "\n",
        "5. **Not Ideal for Complex Models**:\n",
        "   - Logistic Regression may not perform well on very complex datasets, such as those with high non-linearity or requiring sophisticated modeling (e.g., images or time-series data).\n",
        "\n",
        "6. **Limited to Binary Classification (unless extended)**:\n",
        "   - By default, Logistic Regression is used for binary classification. While it can be extended to multiclass classification (e.g., One-vs-Rest, One-vs-One), these extensions can increase complexity.\n",
        "\n"
      ],
      "metadata": {
        "id": "tKTNYOMLnDz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17.What are some use cases of Logistic Regression?**"
      ],
      "metadata": {
        "id": "ps0dVmcinXQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: **Use cases of Logistic Regression**:\n",
        "\n",
        "1. **Medical Diagnosis**: Predicting disease likelihood (e.g., cancer, diabetes).\n",
        "2. **Customer Churn Prediction**: Identifying if a customer will leave a service.\n",
        "3. **Email Spam Detection**: Classifying emails as spam or not.\n",
        "4. **Credit Scoring**: Predicting loan default risk.\n",
        "5. **Sentiment Analysis**: Classifying text as positive or negative.\n",
        "6. **Marketing**: Predicting customer behavior (e.g., ad click, purchase).\n",
        "7. **Fraud Detection**: Identifying fraudulent transactions.\n",
        "8. **Web Traffic Classification**: Predicting user actions (e.g., purchase or sign-up).\n",
        "9. **Election Prediction**: Estimating election outcomes.\n",
        "10. **Purchase Decisions**: Predicting customer purchases.\n",
        "\n",
        "Logistic Regression is widely used for binary and multiclass classification tasks across various industries."
      ],
      "metadata": {
        "id": "K5IiWJKinbQk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18.What is the difference between Softmax Regression and Logistic Regression?**"
      ],
      "metadata": {
        "id": "CVl-DIE_nlV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: Here’s a **precise** comparison between **Softmax Regression** and **Logistic Regression**:\n",
        "\n",
        "1. **Purpose**:\n",
        "   - **Logistic Regression**: Used for **binary classification** (2 classes).\n",
        "   - **Softmax Regression**: Used for **multiclass classification** (more than 2 classes).\n",
        "\n",
        "2. **Output**:\n",
        "   - **Logistic Regression**: Outputs a **single probability** for one class (using **sigmoid**).\n",
        "   - **Softmax Regression**: Outputs a **probability distribution** across all classes (using **softmax**).\n",
        "\n",
        "3. **Mathematical Function**:\n",
        "   - **Logistic Regression**: Uses the **sigmoid function**:  \n",
        "     \\( P(y=1|X) = \\frac{1}{1 + e^{-z}} \\)\n",
        "   - **Softmax Regression**: Uses the **softmax function**:  \n",
        "     \\( P(y=k|X) = \\frac{e^{\\theta_k^T X}}{\\sum_{i=1}^K e^{\\theta_i^T X}} \\)\n",
        "\n",
        "4. **Number of Classes**:\n",
        "   - **Logistic Regression**: **Binary** classification (2 classes).\n",
        "   - **Softmax Regression**: **Multiclass** classification (more than 2 classes).\n",
        "\n",
        "### In Summary:\n",
        "- **Logistic Regression** is for **binary classification** with a single probability output.\n",
        "- **Softmax Regression** is for **multiclass classification** with a probability distribution output across multiple classes."
      ],
      "metadata": {
        "id": "6YuiitgQnsKM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19.How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?**"
      ],
      "metadata": {
        "id": "klkMst1Zn9Kr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans:**Choose One-vs-Rest (OvR)** if:\n",
        "- You have **many classes** and prefer **independent models** for each class.\n",
        "- Your classes are **imbalanced**.\n",
        "- You want to handle classes separately.\n",
        "\n",
        "**Choose Softmax** if:\n",
        "- You want to consider **class relationships** and need a **single model**.\n",
        "- You have a **smaller number of classes**.\n",
        "- Your data is more **balanced** and you want a **probabilistic output**.\n",
        "\n",
        "In short, **OvR** is better for large or imbalanced classes, while **Softmax** is ideal for smaller, balanced datasets with class dependencies."
      ],
      "metadata": {
        "id": "zwD11bP_oCdq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**20.How do we interpret coefficients in Logistic Regression?**"
      ],
      "metadata": {
        "id": "EBSBG6JgoNed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: In **Logistic Regression**, the coefficients represent the relationship between the input features and the **log-odds** of the outcome. Here's how to interpret them:\n",
        "\n",
        "### 1. **Log-Odds Interpretation**:\n",
        "   - The logistic regression model predicts the **log-odds** of the target class.\n",
        "   - The equation is:  \n",
        "     \\[\n",
        "     \\log\\left(\\frac{P(y=1)}{1 - P(y=1)}\\right) = \\theta_0 + \\theta_1 X_1 + \\theta_2 X_2 + \\dots + \\theta_n X_n\n",
        "     \\]\n",
        "     Where \\( \\theta_1, \\theta_2, \\dots, \\theta_n \\) are the coefficients.\n",
        "\n",
        "### 2. **Exponentiation for Odds Ratio**:\n",
        "   - **Exponentiating the coefficient** \\( e^{\\theta_i} \\) gives the **odds ratio** for that feature.\n",
        "   - **Interpretation of Odds Ratio**:\n",
        "     - **If \\( e^{\\theta_i} > 1 \\)**: A one-unit increase in feature \\( X_i \\) increases the odds of the target class (class 1).\n",
        "     - **If \\( e^{\\theta_i} < 1 \\)**: A one-unit increase in feature \\( X_i \\) decreases the odds of the target class (class 1).\n",
        "     - **If \\( e^{\\theta_i} = 1 \\)**: No effect on the odds of the target class.\n",
        "\n",
        "### 3. **Example**:\n",
        "   - Suppose the coefficient for age (\\( \\theta_1 = 0.05 \\)) in a model predicting whether a customer buys a product.\n",
        "   - **Odds Ratio** for age:  \n",
        "     \\[\n",
        "     e^{0.05} \\approx 1.051\n",
        "     \\]\n",
        "     This means for each additional year of age, the odds of the customer buying the product increase by **5.1%**.\n",
        "\n",
        "### 4. **Intercept (θ₀)**:\n",
        "   - The **intercept** \\( \\theta_0 \\) represents the log-odds of the target when all features are zero.\n",
        "   - It serves as the **baseline** log-odds of the outcome."
      ],
      "metadata": {
        "id": "9JalTaEcoTE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Practical:**"
      ],
      "metadata": {
        "id": "YVHfKF5zoqu6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy.**"
      ],
      "metadata": {
        "id": "zwRBvFUgo0NP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target variable\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8MtNfAypAKc",
        "outputId": "7a98741a-f52d-4ef8-b4e1-83707f2bf352"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy.**"
      ],
      "metadata": {
        "id": "7x2GlE4EpUrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target variable\n",
        "\n",
        "# We will perform binary classification by selecting only two classes (0 and 1)\n",
        "X = X[y != 2]  # Remove class 2\n",
        "y = y[y != 2]  # Remove class 2\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model with L1 regularization (Lasso)\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "\n",
        "# Fit the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy with L1 Regularization (Lasso): {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdw-bCwYpufy",
        "outputId": "5cee19f6-c0c4-44a0-edde-cd1223d20932"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L1 Regularization (Lasso): 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients.**"
      ],
      "metadata": {
        "id": "hClzYxZkqK6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target variable\n",
        "\n",
        "# We will perform binary classification by selecting only two classes (0 and 1)\n",
        "X = X[y != 2]  # Remove class 2\n",
        "y = y[y != 2]  # Remove class 2\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model with L2 regularization (Ridge)\n",
        "model = LogisticRegression(penalty='l2', solver='liblinear')\n",
        "\n",
        "# Fit the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy with L2 Regularization (Ridge): {accuracy * 100:.2f}%')\n",
        "\n",
        "# Print the coefficients (weights) of the model\n",
        "print(\"Model Coefficients (weights):\")\n",
        "print(model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzI9AEsPq097",
        "outputId": "42f83962-e548-4f01-a961-c5b6afc862a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L2 Regularization (Ridge): 100.00%\n",
            "Model Coefficients (weights):\n",
            "[[-0.3753915  -1.39664105  2.15250857  0.96423532]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet').**"
      ],
      "metadata": {
        "id": "oCtc09p6rFI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target variable\n",
        "\n",
        "# We will perform binary classification by selecting only two classes (0 and 1)\n",
        "X = X[y != 2]  # Remove class 2\n",
        "y = y[y != 2]  # Remove class 2\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model with Elastic Net regularization\n",
        "# Elastic Net uses both L1 and L2 regularization\n",
        "model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\n",
        "\n",
        "# Fit the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy with Elastic Net Regularization: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Print the coefficients (weights) of the model\n",
        "print(\"Model Coefficients (weights):\")\n",
        "print(model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-aZv4NMrNdC",
        "outputId": "f188dd35-5584-480f-d402-c6275e540675"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Elastic Net Regularization: 100.00%\n",
            "Model Coefficients (weights):\n",
            "[[-0.21425761 -1.56835043  2.32245802  0.69397267]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr.**"
      ],
      "metadata": {
        "id": "xCS0VqzBrcx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target variable (multiclass labels)\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model with One-vs-Rest (OvR) strategy\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear')\n",
        "\n",
        "# Fit the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy with OvR multiclass: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Print the coefficients (weights) of the model\n",
        "print(\"Model Coefficients (weights):\")\n",
        "print(model.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zHISkU2rvaf",
        "outputId": "55ccb605-04d0-4ddf-d4c3-0b3f5a3ee560"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with OvR multiclass: 100.00%\n",
            "Model Coefficients (weights):\n",
            "[[ 0.3711229   1.409712   -2.15210117 -0.95474179]\n",
            " [ 0.49400451 -1.58897112  0.43717015 -1.11187838]\n",
            " [-1.55895271 -1.58893375  2.39874554  2.15556209]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy.**"
      ],
      "metadata": {
        "id": "tpk4STshr_Xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
        "    'penalty': ['l2', 'elasticnet']  # Penalty type\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the model to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and accuracy\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best Cross-validation Accuracy: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = grid_search.best_estimator_.predict(X_test)\n",
        "\n",
        "# Print the test accuracy\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZld_cO4sHtA",
        "outputId": "38d21bc6-4415-492e-ee71-e858d0106738"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 1, 'penalty': 'l2'}\n",
            "Best Cross-validation Accuracy: 0.9619\n",
            "Test Accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "25 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 63, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.86666667        nan 0.93333333        nan 0.96190476        nan\n",
            " 0.94285714        nan 0.95238095        nan]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy.**"
      ],
      "metadata": {
        "id": "nmY_nc_vnaBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracies = []\n",
        "\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the Logistic Regression model\n",
        "    logreg.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = logreg.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy and append it to the accuracies list\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "average_accuracy = np.mean(accuracies)\n",
        "print(f\"Average Accuracy: {average_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDCwQMR-nhmA",
        "outputId": "4b07044c-e872-4dcd-9428-5bf535d83dce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy.**"
      ],
      "metadata": {
        "id": "DKfdQ4Wkn1So"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the dataset from a CSV file\n",
        "data = pd.read_csv('spotify.csv')\n",
        "\n",
        "# Display the first few rows of the dataset (optional)\n",
        "print(data.head())\n",
        "\n",
        "# Handle non-numeric data:\n",
        "# 1. Convert any categorical columns to numeric using Label Encoding or One-Hot Encoding.\n",
        "# Assuming 'Artist' and 'Track Name' are categorical columns\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Example of encoding categorical columns\n",
        "data['Artist'] = label_encoder.fit_transform(data['Artist'])\n",
        "data['Track Name'] = label_encoder.fit_transform(data['Track Name'])\n",
        "\n",
        "# If the 'Track ID' column is non-numeric, you may want to drop it (it doesn't affect the model)\n",
        "data = data.drop(columns=['Track ID'])\n",
        "\n",
        "# Now, the dataset should only have numeric columns.\n",
        "# Assuming the last column is the target variable (if the target is Popularity, for example):\n",
        "X = data.iloc[:, :-1].values  # Features (excluding the last column)\n",
        "y = data.iloc[:, -1].values   # Target variable (last column, e.g., 'Popularity')\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define and train the Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qt4XTpSpPUM",
        "outputId": "bb67377b-7757-4cfc-dc2f-1e579f52bbd1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Artist                               Track Name  Popularity  Duration (ms)  \\\n",
            "0  Drake  Rich Baby Daddy (feat. Sexyy Red & SZA)          92         319191   \n",
            "1  Drake                                One Dance          91         173986   \n",
            "2  Drake                       IDGAF (feat. Yeat)          90         260111   \n",
            "3  Drake     First Person Shooter (feat. J. Cole)          88         247444   \n",
            "4  Drake            Jimmy Cooks (feat. 21 Savage)          88         218364   \n",
            "\n",
            "                 Track ID  \n",
            "0  1yeB8MUNeLo9Ek1UEpsyz6  \n",
            "1  1zi7xx7UVEFkmKfv06H8x0  \n",
            "2  2YSzYUF3jWqb9YP9VXmpjE  \n",
            "3  7aqfrAY2p9BUSiupwk3svU  \n",
            "4  3F5CgOj3wFlRv51JsHbxhe  \n",
            "Accuracy: 0.0909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression.Print the best parameters and accuracy.**"
      ],
      "metadata": {
        "id": "lsNcU_6ApYM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Load and preprocess data (replace 'spotify.csv' with your dataset)\n",
        "data = pd.read_csv('spotify.csv')\n",
        "\n",
        "# Encoding categorical features (example: 'Artist' and 'Track Name' as categorical)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "data['Artist'] = label_encoder.fit_transform(data['Artist'])\n",
        "data['Track Name'] = label_encoder.fit_transform(data['Track Name'])\n",
        "\n",
        "# Drop non-numeric columns (e.g., 'Track ID')\n",
        "data = data.drop(columns=['Track ID'])\n",
        "\n",
        "# Features and target\n",
        "X = data.iloc[:, :-1]  # Features (all columns except the last one)\n",
        "y = data.iloc[:, -1]   # Target (last column, e.g., 'Popularity')\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Define parameter distribution for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'C': uniform(loc=0.1, scale=10),  # Regularization strength (C)\n",
        "    'penalty': ['l1', 'l2'],  # Regularization type\n",
        "    'solver': ['liblinear', 'saga']  # Solvers for optimization\n",
        "}\n",
        "\n",
        "# Apply StratifiedKFold for RandomizedSearchCV\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)  # Use fewer splits if needed\n",
        "\n",
        "# Apply RandomizedSearchCV with StratifiedKFold\n",
        "random_search = RandomizedSearchCV(estimator=logreg, param_distributions=param_dist, n_iter=100, cv=cv, n_jobs=-1, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found by RandomizedSearchCV\n",
        "print(f\"Best Parameters: {random_search.best_params_}\")\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = random_search.best_estimator_.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZqL31IVuf0p",
        "outputId": "d3d82c52-f1fe-4e69-c48e-9984d0ed3ecf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 8.387375091519294, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Accuracy: 0.0114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10.Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy.**"
      ],
      "metadata": {
        "id": "z8d4yx1QsVuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load and preprocess the dataset (replace 'spotify.csv' with your actual dataset)\n",
        "data = pd.read_csv('spotify.csv')\n",
        "\n",
        "# Encoding categorical features\n",
        "label_encoder = LabelEncoder()\n",
        "data['Artist'] = label_encoder.fit_transform(data['Artist'])\n",
        "data['Track Name'] = label_encoder.fit_transform(data['Track Name'])\n",
        "data = data.drop(columns=['Track ID'])  # Drop non-numeric column\n",
        "\n",
        "# Features and target\n",
        "X = data.iloc[:, :-1]  # Features (all columns except the last one)\n",
        "y = data.iloc[:, -1]   # Target (last column, e.g., 'Popularity')\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# One-vs-One Multiclass classification\n",
        "ovo_classifier = OneVsOneClassifier(logreg)\n",
        "\n",
        "# Fit the model\n",
        "ovo_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = ovo_classifier.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27CP-dXYshGA",
        "outputId": "6af95e9f-0016-4fca-9cc8-1a64abf62a07"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11.Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification.**"
      ],
      "metadata": {
        "id": "dwmgw8tkv26w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess data (replace 'your_dataset.csv' with your dataset)\n",
        "data = pd.read_csv('spotify.csv')  # Example dataset\n",
        "\n",
        "# Encoding categorical features (for example, if 'Artist' is categorical)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "data['Artist'] = label_encoder.fit_transform(data['Artist'])\n",
        "data['Track Name'] = label_encoder.fit_transform(data['Track Name'])\n",
        "\n",
        "# Drop non-numeric columns (e.g., 'Track ID')\n",
        "data = data.drop(columns=['Track ID'])\n",
        "\n",
        "# Features and target (assuming 'Popularity' is binary, you may need to adjust this)\n",
        "X = data.iloc[:, :-1]  # Features (all columns except the last one)\n",
        "y = data.iloc[:, -1]   # Target variable (binary classification: last column)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define and train the Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix using seaborn\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.title('Confusion Matrix for Logistic Regression')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "id": "Frz6K8u7wESn",
        "outputId": "c704d581-4918-4bc3-ac8d-785d6bcf8071"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12.Write a Python program to train a Logistic Regression model and evaluate its performance using Precision,Recall,and F1-Score.**"
      ],
      "metadata": {
        "id": "vOhr6_4PwZuK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lyMmmoVZPDr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "432ac9af-6a37-49fb-aced-585b41e5200e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.0511\n",
            "Recall: 0.0568\n",
            "F1-Score: 0.0530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Load and preprocess data (replace 'your_dataset.csv' with your dataset)\n",
        "data = pd.read_csv('spotify.csv')  # Example dataset\n",
        "\n",
        "# Encoding categorical features (for example, if 'Artist' is categorical)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "data['Artist'] = label_encoder.fit_transform(data['Artist'])\n",
        "data['Track Name'] = label_encoder.fit_transform(data['Track Name'])\n",
        "\n",
        "# Drop non-numeric columns (e.g., 'Track ID')\n",
        "data = data.drop(columns=['Track ID'])\n",
        "\n",
        "# Features and target (assuming 'Popularity' is multiclass, you may need to adjust this)\n",
        "X = data.iloc[:, :-1]  # Features (all columns except the last one)\n",
        "y = data.iloc[:, -1]   # Target variable (multiclass classification: last column)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define and train the Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=1000, multi_class='ovr')  # Using One-vs-Rest for multiclass\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score with multiclass settings\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the results\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13.Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance.**"
      ],
      "metadata": {
        "id": "zQ0je0uaw-wS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Example of an imbalanced dataset (Replace with your actual dataset)\n",
        "# Load the data (replace 'your_dataset.csv' with your own CSV file)\n",
        "data = pd.read_csv('spotify.csv')\n",
        "\n",
        "# Encoding categorical features (e.g., 'Artist' and 'Track Name')\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "data['Artist'] = label_encoder.fit_transform(data['Artist'])\n",
        "data['Track Name'] = label_encoder.fit_transform(data['Track Name'])\n",
        "\n",
        "# Drop non-numeric columns (e.g., 'Track ID')\n",
        "data = data.drop(columns=['Track ID'])\n",
        "\n",
        "# Features and target (assuming 'Popularity' is multiclass, not binary)\n",
        "X = data.iloc[:, :-1]  # Features (all columns except the last one)\n",
        "y = data.iloc[:, -1]   # Target variable (multiclass classification: last column)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Logistic Regression model with class weights ('balanced')\n",
        "logreg = LogisticRegression(max_iter=1000, class_weight='balanced', multi_class='ovr')\n",
        "\n",
        "# Train the model\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score for multiclass (set the `average` parameter)\n",
        "precision = precision_score(y_test, y_pred, average='macro')  # Options: 'micro', 'macro', 'weighted'\n",
        "recall = recall_score(y_test, y_pred, average='macro')        # Options: 'micro', 'macro', 'weighted'\n",
        "f1 = f1_score(y_test, y_pred, average='macro')                # Options: 'micro', 'macro', 'weighted'\n",
        "\n",
        "# Print the results\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glMMS_s8xb8b",
        "outputId": "de4d9653-4598-4128-be21-ff5045c4cf31"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.0065\n",
            "Recall: 0.0065\n",
            "F1-Score: 0.0065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14.Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values,and evaluate performance.**"
      ],
      "metadata": {
        "id": "TEjogvGTxhBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Titanic dataset\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())\n",
        "\n",
        "# Handle missing values\n",
        "# Use SimpleImputer to fill missing numeric values with the median\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "data[['Age', 'Fare']] = imputer.fit_transform(data[['Age', 'Fare']])\n",
        "\n",
        "# Fill missing categorical values ('Embarked' and 'Cabin') with the most frequent category\n",
        "data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
        "\n",
        "# Drop columns that won't be used in the model (e.g., 'Name', 'Ticket', 'Cabin', 'PassengerId')\n",
        "data = data.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'])\n",
        "\n",
        "# Encode categorical features (e.g., 'Sex' and 'Embarked')\n",
        "label_encoder = LabelEncoder()\n",
        "data['Sex'] = label_encoder.fit_transform(data['Sex'])\n",
        "data['Embarked'] = label_encoder.fit_transform(data['Embarked'])\n",
        "\n",
        "# Features (X) and target variable (y)\n",
        "X = data.drop(columns='Survived')  # Features (everything except 'Survived')\n",
        "y = data['Survived']  # Target variable (Survived: 1 or 0)\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features (optional but can help with model performance)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LipmNHD9xn8P",
        "outputId": "b3b36cfa-ffc8-4cfd-d414-bc3db50c7f1d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "Accuracy: 0.8045\n",
            "Precision: 0.7826\n",
            "Recall: 0.7297\n",
            "F1-Score: 0.7552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15.Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model.Evaluate its accuracy and compare results with and without scaling.**"
      ],
      "metadata": {
        "id": "Wgda7fIgz9Xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Titanic dataset\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Handle missing values\n",
        "# Use SimpleImputer to fill missing numeric values with the median\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "data[['Age', 'Fare']] = imputer.fit_transform(data[['Age', 'Fare']])\n",
        "\n",
        "# Fill missing categorical values ('Embarked') with the most frequent category\n",
        "data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
        "\n",
        "# Drop columns that won't be used in the model (e.g., 'Name', 'Ticket', 'Cabin', 'PassengerId')\n",
        "data = data.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'])\n",
        "\n",
        "# Encode categorical features (e.g., 'Sex' and 'Embarked')\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "data['Sex'] = label_encoder.fit_transform(data['Sex'])\n",
        "data['Embarked'] = label_encoder.fit_transform(data['Embarked'])\n",
        "\n",
        "# Features (X) and target variable (y)\n",
        "X = data.drop(columns='Survived')  # Features (everything except 'Survived')\n",
        "y = data['Survived']  # Target variable (Survived: 1 or 0)\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1. Model without scaling\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy for the model without scaling\n",
        "y_pred = logreg.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy without scaling: {accuracy_no_scaling:.4f}\")\n",
        "\n",
        "# 2. Model with scaling (Standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)  # Fit and transform on training data\n",
        "X_test_scaled = scaler.transform(X_test)  # Transform on test data using the scaler\n",
        "\n",
        "# Train the model with scaled features\n",
        "logreg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy for the model with scaling\n",
        "y_pred_scaled = logreg.predict(X_test_scaled)\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred_scaled)\n",
        "print(f\"Accuracy with scaling: {accuracy_with_scaling:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PysgNVVo0Iat",
        "outputId": "88fe2fea-7a3b-47a9-8653-591c32c0fc65"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.8101\n",
            "Accuracy with scaling: 0.8045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16.Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score.**"
      ],
      "metadata": {
        "id": "tD7632aQ0Vxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Titanic dataset\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Handle missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "data[['Age', 'Fare']] = imputer.fit_transform(data[['Age', 'Fare']])\n",
        "\n",
        "# Fill missing categorical values ('Embarked') with the most frequent category\n",
        "data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
        "\n",
        "# Drop columns that won't be used in the model (e.g., 'Name', 'Ticket', 'Cabin', 'PassengerId')\n",
        "data = data.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'])\n",
        "\n",
        "# Encode categorical features (e.g., 'Sex' and 'Embarked')\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "data['Sex'] = label_encoder.fit_transform(data['Sex'])\n",
        "data['Embarked'] = label_encoder.fit_transform(data['Embarked'])\n",
        "\n",
        "# Features (X) and target variable (y)\n",
        "X = data.drop(columns='Survived')  # Features (everything except 'Survived')\n",
        "y = data['Survived']  # Target variable (Survived: 1 or 0)\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (feature scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict probabilities for the positive class (1)\n",
        "y_pred_prob = logreg.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Calculate the ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
        "\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwrz6bge0a7c",
        "outputId": "4230a89f-c018-4218-900f-df830db5206f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.8819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17.Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy.**"
      ],
      "metadata": {
        "id": "3AvNCmkN0lEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Titanic dataset (or use your own dataset)\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Handle missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "data[['Age', 'Fare']] = imputer.fit_transform(data[['Age', 'Fare']])\n",
        "\n",
        "# Fill missing categorical values ('Embarked') with the most frequent category\n",
        "data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
        "\n",
        "# Drop columns that won't be used in the model (e.g., 'Name', 'Ticket', 'Cabin', 'PassengerId')\n",
        "data = data.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'])\n",
        "\n",
        "# Encode categorical features (e.g., 'Sex' and 'Embarked')\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "data['Sex'] = label_encoder.fit_transform(data['Sex'])\n",
        "data['Embarked'] = label_encoder.fit_transform(data['Embarked'])\n",
        "\n",
        "# Features (X) and target variable (y)\n",
        "X = data.drop(columns='Survived')  # Features (everything except 'Survived')\n",
        "y = data['Survived']  # Target variable (Survived: 1 or 0)\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (feature scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the Logistic Regression model with a custom learning rate (C=0.5)\n",
        "logreg = LogisticRegression(C=0.5, max_iter=1000)\n",
        "logreg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = logreg.predict(X_test_scaled)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qkuUBWz01w5",
        "outputId": "f1284649-cc6b-444b-b913-5b2959bb11ed"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18.Write a Python program to train Logistic Regression and identify important features based on model coefficients.**"
      ],
      "metadata": {
        "id": "txl4-lZ81CFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the Titanic dataset (or use your own dataset)\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "data[['Age', 'Fare']] = imputer.fit_transform(data[['Age', 'Fare']])\n",
        "\n",
        "# Fill missing categorical values ('Embarked') with the most frequent category\n",
        "data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
        "\n",
        "# Drop columns that won't be used in the model (e.g., 'Name', 'Ticket', 'Cabin', 'PassengerId')\n",
        "data = data.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'])\n",
        "\n",
        "# Encode categorical features (e.g., 'Sex' and 'Embarked')\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "data['Sex'] = label_encoder.fit_transform(data['Sex'])\n",
        "data['Embarked'] = label_encoder.fit_transform(data['Embarked'])\n",
        "\n",
        "# Features (X) and target variable (y)\n",
        "X = data.drop(columns='Survived')  # Features (everything except 'Survived')\n",
        "y = data['Survived']  # Target variable (Survived: 1 or 0)\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (feature scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get the model coefficients\n",
        "coefficients = logreg.coef_[0]\n",
        "\n",
        "# Map the coefficients to feature names\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Coefficient': coefficients\n",
        "})\n",
        "\n",
        "# Sort the features by the absolute value of their coefficients\n",
        "feature_importance['AbsCoefficient'] = feature_importance['Coefficient'].abs()\n",
        "feature_importance = feature_importance.sort_values(by='AbsCoefficient', ascending=False)\n",
        "\n",
        "# Print the most important features\n",
        "print(\"Important Features based on model coefficients:\")\n",
        "print(feature_importance[['Feature', 'Coefficient']])\n",
        "\n",
        "# Optionally, plot the coefficients\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importance['Feature'], feature_importance['Coefficient'])\n",
        "plt.xlabel('Coefficient Value')\n",
        "plt.title('Logistic Regression Coefficients')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "zBYRr4rz1H_z",
        "outputId": "ef853999-aaa5-4084-be10-a0bc2e4e1a15"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Important Features based on model coefficients:\n",
            "    Feature  Coefficient\n",
            "1       Sex    -1.278865\n",
            "0    Pclass    -0.782061\n",
            "2       Age    -0.395574\n",
            "3     SibSp    -0.349582\n",
            "6  Embarked    -0.170860\n",
            "5      Fare     0.126216\n",
            "4     Parch    -0.098292\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19.Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa Score.**"
      ],
      "metadata": {
        "id": "_PdaPpUf1Trs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the Titanic dataset (or use your own dataset)\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "data[['Age', 'Fare']] = imputer.fit_transform(data[['Age', 'Fare']])\n",
        "\n",
        "# Fill missing categorical values ('Embarked') with the most frequent category\n",
        "data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
        "\n",
        "# Drop columns that won't be used in the model (e.g., 'Name', 'Ticket', 'Cabin', 'PassengerId')\n",
        "data = data.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'])\n",
        "\n",
        "# Encode categorical features (e.g., 'Sex' and 'Embarked')\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "data['Sex'] = label_encoder.fit_transform(data['Sex'])\n",
        "data['Embarked'] = label_encoder.fit_transform(data['Embarked'])\n",
        "\n",
        "# Features (X) and target variable (y)\n",
        "X = data.drop(columns='Survived')  # Features (everything except 'Survived')\n",
        "y = data['Survived']  # Target variable (Survived: 1 or 0)\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (feature scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = logreg.predict(X_test_scaled)\n",
        "\n",
        "# Calculate Cohen's Kappa Score\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "# Print the Cohen's Kappa Score\n",
        "print(f\"Cohen's Kappa Score: {kappa:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQfStFES1bov",
        "outputId": "a2d9ad67-e565-4cbb-ec37-be969317a4f3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa Score: 0.5928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**20.Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification.**"
      ],
      "metadata": {
        "id": "P2k4c0Yg16uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the Titanic dataset (or use your own dataset)\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "data[['Age', 'Fare']] = imputer.fit_transform(data[['Age', 'Fare']])\n",
        "\n",
        "# Fill missing categorical values ('Embarked') with the most frequent category\n",
        "data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
        "\n",
        "# Drop columns that won't be used in the model (e.g., 'Name', 'Ticket', 'Cabin', 'PassengerId')\n",
        "data = data.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'])\n",
        "\n",
        "# Encode categorical features (e.g., 'Sex' and 'Embarked')\n",
        "label_encoder = LabelEncoder()\n",
        "data['Sex'] = label_encoder.fit_transform(data['Sex'])\n",
        "data['Embarked'] = label_encoder.fit_transform(data['Embarked'])\n",
        "\n",
        "# Features (X) and target variable (y)\n",
        "X = data.drop(columns='Survived')  # Features (everything except 'Survived')\n",
        "y = data['Survived']  # Target variable (Survived: 1 or 0)\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (feature scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict probabilities for the test set\n",
        "y_probs = logreg.predict_proba(X_test_scaled)[:, 1]  # Get probabilities for the positive class (Survived=1)\n",
        "\n",
        "# Calculate precision, recall, and thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
        "\n",
        "# Plot the Precision-Recall curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, color='blue', label='Precision-Recall Curve')\n",
        "plt.fill_between(recall, precision, color='blue', alpha=0.2)\n",
        "plt.title('Precision-Recall Curve for Logistic Regression')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Calculate Average Precision Score\n",
        "average_precision = average_precision_score(y_test, y_probs)\n",
        "print(f'Average Precision Score: {average_precision:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "M2q0uLHj2AZi",
        "outputId": "563e66f4-b894-487f-d868-ba30444fe61c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Precision Score: 0.8795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**21.Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy.**"
      ],
      "metadata": {
        "id": "f6UjUsFx2LUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define solvers to compare\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "accuracies = {}\n",
        "\n",
        "# Train and evaluate Logistic Regression with different solvers\n",
        "for solver in solvers:\n",
        "    # Create Logistic Regression model with the specified solver\n",
        "    model = LogisticRegression(solver=solver, max_iter=200)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies[solver] = accuracy\n",
        "\n",
        "# Print the accuracy for each solver\n",
        "for solver, accuracy in accuracies.items():\n",
        "    print(f\"Accuracy with solver '{solver}': {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5yMiYTE2SEh",
        "outputId": "85e405b4-9268-4271-9c83-fac1bac5124b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with solver 'liblinear': 1.0000\n",
            "Accuracy with solver 'saga': 1.0000\n",
            "Accuracy with solver 'lbfgs': 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**22.Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC).**"
      ],
      "metadata": {
        "id": "tPMpZuBd2d_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target variable\n",
        "\n",
        "# Since MCC is used for binary classification, let's focus on classifying two classes (Setosa and Non-Setosa)\n",
        "y_binary = (y == 0).astype(int)  # Classifying Setosa as 1, and other classes as 0\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define and train the Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=200)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Calculate the Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "# Print the MCC score\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ1_o-cJ2j_E",
        "outputId": "5b6dd40d-a891-4c5b-8c21-8717224d02f8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient (MCC): 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**23.Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling.**"
      ],
      "metadata": {
        "id": "CEWdXzkh2tWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1. Train Logistic Regression on Raw Data\n",
        "logreg_raw = LogisticRegression(max_iter=200)\n",
        "logreg_raw.fit(X_train, y_train)\n",
        "y_pred_raw = logreg_raw.predict(X_test)\n",
        "\n",
        "# 2. Standardize the data (Feature scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression on Scaled Data\n",
        "logreg_scaled = LogisticRegression(max_iter=200)\n",
        "logreg_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = logreg_scaled.predict(X_test_scaled)\n",
        "\n",
        "# Calculate and compare accuracy for both raw and standardized data\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy on Raw Data: {accuracy_raw:.4f}\")\n",
        "print(f\"Accuracy on Scaled Data: {accuracy_scaled:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efgl6t202zSi",
        "outputId": "6acca1df-cdd7-4bbd-91b4-8756d71abde7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Raw Data: 1.0000\n",
            "Accuracy on Scaled Data: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**24.Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation.**"
      ],
      "metadata": {
        "id": "YwEFw_-o28AV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Define the hyperparameters for tuning (the C parameter)\n",
        "param_grid = {'C': np.logspace(-4, 4, 20)}  # 20 values from 10^-4 to 10^4 for C\n",
        "\n",
        "# Apply GridSearchCV with 5-fold cross-validation to find the optimal C\n",
        "grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameter (C) and its corresponding accuracy\n",
        "best_C = grid_search.best_params_['C']\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Print the best C value found\n",
        "print(f\"Best C value: {best_C}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy of the model with the best C\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51SS10-r3D5u",
        "outputId": "37cf3197-7387-4392-cc64-4358377096c8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best C value: 0.615848211066026\n",
            "Test Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**25.Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions.**"
      ],
      "metadata": {
        "id": "pu5fLq313N_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=200)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model using joblib\n",
        "joblib.dump(logreg, 'logistic_regression_model.pkl')\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = joblib.load('logistic_regression_model.pkl')\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of the loaded model: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3sOTuJo3TIh",
        "outputId": "f043cdb4-2278-4126-d407-97769f5ceda9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the loaded model: 1.0000\n"
          ]
        }
      ]
    }
  ]
}